{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Resources/tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tidy_tweet'].astype(str)\n",
    "ylabels = (df['target']/4).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:10000]\n",
    "y_val = y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 144s 3s/step - loss: 0.5114 - accuracy: 0.7628 - val_loss: 0.4049 - val_accuracy: 0.7758\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 157s 4s/step - loss: 0.3627 - accuracy: 0.8411 - val_loss: 0.3210 - val_accuracy: 0.8656\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 166s 4s/step - loss: 0.3049 - accuracy: 0.8729 - val_loss: 0.2682 - val_accuracy: 0.8891\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 179s 4s/step - loss: 0.2548 - accuracy: 0.8993 - val_loss: 0.2062 - val_accuracy: 0.9250\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 177s 4s/step - loss: 0.1976 - accuracy: 0.9282 - val_loss: 0.1465 - val_accuracy: 0.9556\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 171s 4s/step - loss: 0.1471 - accuracy: 0.9509 - val_loss: 0.1038 - val_accuracy: 0.9675\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 167s 4s/step - loss: 0.1010 - accuracy: 0.9698 - val_loss: 0.0749 - val_accuracy: 0.9817\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 180s 4s/step - loss: 0.0726 - accuracy: 0.9799 - val_loss: 0.0527 - val_accuracy: 0.9862\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 179s 4s/step - loss: 0.0546 - accuracy: 0.9855 - val_loss: 0.0417 - val_accuracy: 0.9886\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 179s 4s/step - loss: 0.0432 - accuracy: 0.9885 - val_loss: 0.0327 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Path 'saved_model' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-69afa542c09e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#Save so that we can easily load this in MLflow later if we need to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     mlflow.sklearn.save_model(model, \"saved_model\", \n\u001b[1;32m---> 25\u001b[1;33m                               serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlflow\\sklearn.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(sk_model, path, conda_env, mlflow_model, serialization_format, signature, input_example)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         raise MlflowException(message=\"Path '{}' already exists\".format(path),\n\u001b[1;32m--> 146\u001b[1;33m                               error_code=RESOURCE_ALREADY_EXISTS)\n\u001b[0m\u001b[0;32m    147\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmlflow_model\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMlflowException\u001b[0m: Path 'saved_model' already exists"
     ]
    }
   ],
   "source": [
    "run_name = \"Twitter_Sentiment\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "    hub_layer = hub.KerasLayer(model, output_shape=[512], input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=20000,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "    #Save so that we can easily load this in MLflow later if we need to\n",
    "    mlflow.sklearn.save_model(model, \"saved_model\", \n",
    "                              serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n",
    "    mlflow.log_artifact(\"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat saved_model/conda.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
